[project]
name = "docs-to-eval"
version = "0.1.0"
description = "Automated LLM Evaluation System - Generate domain-specific benchmarks and evaluate LLMs"
authors = [
    {name = "docs-to-eval", email = "noreply@example.com"}
]
readme = "README.md"
requires-python = ">=3.11"
keywords = ["llm", "evaluation", "benchmarking", "nlp", "ai"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Testing",
]
dependencies = [
    "requests>=2.32.5",
    "beautifulsoup4>=4.14.2",
    "typer>=0.19.2",
    "rich>=14.2.0",
    "fastapi>=0.119.0",
    "uvicorn>=0.37.0",
    "websockets>=15.0.1",
    "pyyaml>=6.0.3",
    "python-multipart>=0.0.20",
    "httpx>=0.28.1",
    "pydantic>=2.12.3",
    "math-verify[antlr4-13-2]>=0.8.0",
    "numpy>=2.3.4",
    "chonkie[all]>=1.4.0",
    "sentence-transformers>=5.1.1",
    "python-dotenv>=1.0.1",
    "openai>=2.5.0",
    "mlx>=0.29.3",
    "tiktoken>=0.12.0",
    "pytest>=8.4.2",
    "irouter>=0.3.1",
    "google-generativeai>=0.8.5",
    "transformers>=4.48.0",
    "torch>=2.5.1",
    "accelerate>=1.2.1",
]



[project.scripts]
docs-to-eval = "docs_to_eval.cli.main:main_cli"

[project.urls]
Homepage = "https://github.com/s-smits/docs-to-eval"
Repository = "https://github.com/s-smits/docs-to-eval"
Documentation = "https://github.com/s-smits/docs-to-eval#readme"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["docs_to_eval"]

[dependency-groups]
dev = [
    "pytest>=8.4.2",
    "pytest-asyncio>=1.2.0",
    "ruff>=0.9.0",
    "black>=25.1.0",
]
